{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Competition - Data Exploration\n",
    "\n",
    "Welcome to the CIFAR-10 image classification competition!\n",
    "\n",
    "**Goal:** Build a CNN that achieves the highest accuracy on the augmented test set.\n",
    "\n",
    "**Dataset:** CIFAR-10 has 10 classes of 32Ã—32 color images.\n",
    "\n",
    "**What You'll Do:**\n",
    "1. Explore the CIFAR-10 dataset in this notebook\n",
    "2. Modify `model.py` to improve the CNN architecture\n",
    "3. Modify `main.py` to add data augmentations\n",
    "4. Run `python main.py` to train and generate `submission.csv`\n",
    "5. Submit `submission.csv` to Kaggle\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \n",
    "                      'mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Load and Explore CIFAR-10\n",
    "\n",
    "CIFAR-10 is a classic image classification dataset:\n",
    "- 10 classes: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, truck\n",
    "- Same tiny 32Ã—32 pixel images\n",
    "- 5,000 training images per class (50,000 total)\n",
    "- 1,000 test images per class (10,000 total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "basic_transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=basic_transform)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=basic_transform)\n",
    "\n",
    "# CIFAR-10 class names\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f'Training images: {len(train_dataset)}')\n",
    "print(f'Test images: {len(test_dataset)}')\n",
    "print(f'Number of classes: {len(classes)}')\n",
    "print(f'Classes: {classes}')\n",
    "print(f'Image shape: {train_dataset[0][0].shape}')  # (3, 32, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Visualize Random Samples\n",
    "\n",
    "Let's see what kinds of images we're working with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random samples from the training set\n",
    "fig, axes = plt.subplots(4, 8, figsize=(16, 8))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = train_dataset[np.random.randint(len(train_dataset))]\n",
    "    ax.imshow(img.permute(1, 2, 0))  # Convert from (C, H, W) to (H, W, C)\n",
    "    ax.set_title(f'{classes[label]}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Random CIFAR-10 Training Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('\\nCIFAR-10 has 10 different classes!')\n",
    "print('The competition will test your model on AUGMENTED versions of these images.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Class Distribution\n",
    "\n",
    "Let's verify that the dataset is balanced (equal number of images per class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count images per class in training set\n",
    "train_labels = [label for _, label in train_dataset]\n",
    "label_counts = Counter(train_labels)\n",
    "\n",
    "# Plot distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(classes)), [label_counts[i] for i in range(len(classes))], \n",
    "        color='steelblue', alpha=0.7, tick_label=classes)\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('CIFAR-10 Training Set - Class Distribution')\n",
    "plt.axhline(y=5000, color='red', linestyle='--', label='Expected: 5,000 per class')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Total classes: {len(label_counts)}')\n",
    "print(f'Images per class: {label_counts[0]}')\n",
    "print('Dataset is balanced!' if len(set(label_counts.values())) == 1 else 'Dataset is imbalanced!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Image Statistics\n",
    "\n",
    "Understanding pixel value distributions helps us choose good normalization strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 1000 random images and compute statistics\n",
    "sample_images = [train_dataset[i][0] for i in np.random.choice(len(train_dataset), 1000, replace=False)]\n",
    "sample_tensor = torch.stack(sample_images)\n",
    "\n",
    "# Compute mean and std per channel\n",
    "mean = sample_tensor.mean(dim=[0, 2, 3])\n",
    "std = sample_tensor.std(dim=[0, 2, 3])\n",
    "\n",
    "print('Pixel Statistics (from 1000 random images):')\n",
    "print(f'Mean (R, G, B): {mean.numpy()}')\n",
    "print(f'Std  (R, G, B): {std.numpy()}')\n",
    "print('\\nNote: Values are in [0, 1] range after ToTensor()')\n",
    "print('These statistics can be used for normalization in your transforms!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Visualize Samples from Specific Classes\n",
    "\n",
    "Let's look at multiple samples from the same class to understand intra-class variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random class\n",
    "target_class = np.random.randint(0, 10)\n",
    "\n",
    "# Find all images from this class\n",
    "class_images = [(img, label) for img, label in train_dataset if label == target_class][:16]\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(class_images):\n",
    "        img, label = class_images[i]\n",
    "        ax.imshow(img.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "plt.suptitle(f'16 Samples from Class: {classes[target_class]}', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'Notice the variation within the same class!')\n",
    "print(f'Different angles, lighting, colors - this is why data augmentation helps!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Compare with Test Set\n",
    "\n",
    "Let's visualize some test images to see if they look different from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test samples\n",
    "fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img, label = test_dataset[np.random.randint(len(test_dataset))]\n",
    "    ax.imshow(img.permute(1, 2, 0))\n",
    "    ax.set_title(f'{classes[label]}', fontsize=8)\n",
    "    ax.axis('off')\n",
    "plt.suptitle('Random CIFAR-10 Test Samples', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Standard CIFAR-10 test set looks similar to training set.')\n",
    "print('However, the COMPETITION test set will have augmentations!')\n",
    "print('(noise, blur, color shifts, rotations, etc.)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Training Your Model\n",
    "\n",
    "Now that you've explored the data, it's time to build and train your model!\n",
    "\n",
    "### 1. Improve the Model (`model.py`)\n",
    "- Add more convolutional layers\n",
    "- Add BatchNorm for better training\n",
    "- Try different architectures\n",
    "- Experiment with dropout rates\n",
    "\n",
    "### 2. Add Data Augmentation (`main.py`)\n",
    "**This is KEY to success!** The competition test set has augmentations.\n",
    "\n",
    "Suggested augmentations in `get_transforms()`:\n",
    "```python\n",
    "transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3)\n",
    "transforms.RandomRotation(15)\n",
    "transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n",
    "transforms.RandomGrayscale(p=0.1)\n",
    "```\n",
    "\n",
    "### 3. Train the Model\n",
    "```bash\n",
    "python main.py --epochs 20\n",
    "```\n",
    "\n",
    "This will:\n",
    "- Train your model for the specified epochs\n",
    "- Save the best model as `best_model.pth`\n",
    "- Generate `submission.csv` for Kaggle (if test.csv and test_images/ are present)\n",
    "\n",
    "### 4. Submit to Kaggle\n",
    "1. Download `test.csv` and `test_images.zip` from Kaggle\n",
    "2. Unzip `test_images.zip` in the `cifar10_comp/` folder\n",
    "3. Run `python main.py --epochs 20` to generate `submission.csv`\n",
    "4. Upload `submission.csv` to Kaggle!\n",
    "\n",
    "---\n",
    "\n",
    "## Tips for Success ðŸ’¡\n",
    "\n",
    "1. **Data Augmentation is CRITICAL!** The test set has augmentations.\n",
    "2. Train for 15-30 epochs for better performance\n",
    "3. Experiment with different learning rates and optimizers\n",
    "4. Add BatchNorm to your model architecture\n",
    "5. Monitor training vs test accuracy to detect overfitting\n",
    "\n",
    "Good luck! ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
